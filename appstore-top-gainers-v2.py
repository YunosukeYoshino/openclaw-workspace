#!/usr/bin/env python3
"""
App Store Top Gainers ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ v2
RSS APIã‚’æ”¹è‰¯ã—ã€ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ã‚’å¼·åŒ–
"""

import sqlite3
import json
import urllib.request
import urllib.parse
import urllib.error
import re
import time
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import os
import random

def debug_print(msg):
    print(msg)
    sys.stdout.flush()


class AppStoreAnalyzerV2:
    """App Store ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ v2"""

    def __init__(self, db_path: str = None):
        if db_path is None:
            db_path = os.path.join(
                os.path.dirname(__file__),
                "data",
                "appstore_gainers.db"
            )
        self.db_path = db_path
        self._init_db()

    def _connect(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        return sqlite3.connect(self.db_path)

    def _init_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        conn = self._connect()
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS apps (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                app_id TEXT UNIQUE NOT NULL,
                name TEXT NOT NULL,
                developer TEXT,
                category TEXT,
                rating REAL,
                url TEXT,
                discovered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS reviews (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                app_id INTEGER NOT NULL,
                title TEXT,
                text TEXT,
                rating INTEGER,
                author TEXT,
                review_date TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (app_id) REFERENCES apps(id)
            )
        ''')

        conn.commit()
        conn.close()

    def get_reviews_with_retry(self, app_id: str, country: str = 'us',
                                 max_retries: int = 3, base_timeout: int = 30) -> List[Dict]:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ä»˜ãï¼‰"""
        url = f"https://itunes.apple.com/{country}/rss/customerreviews/id={app_id}/sortBy=mostRecent/xml"

        for attempt in range(1, max_retries + 1):
            timeout = base_timeout * attempt  # ãƒªãƒˆãƒ©ã‚¤ã”ã¨ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å¢—ã‚„ã™

            try:
                debug_print(f"      ãƒªãƒˆãƒ©ã‚¤ {attempt}/{max_retries}: timeout={timeout}ç§’")
                debug_print(f"      URL: {url[:80]}...")

                with urllib.request.urlopen(url, timeout=timeout) as response:
                    xml_data = response.read().decode('utf-8')

                debug_print(f"      âœ… XMLå–å¾—å®Œäº†: {len(xml_data)} ãƒã‚¤ãƒˆ")

                # XMLã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡º
                reviews = self._parse_xml_reviews(xml_data)
                debug_print(f"      âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼æŠ½å‡º: {len(reviews)} ä»¶")

                return reviews

            except urllib.error.HTTPError as e:
                debug_print(f"      âš ï¸ HTTPã‚¨ãƒ©ãƒ¼: {e.code} {e.reason}")
                if attempt < max_retries:
                    debug_print(f"      {attempt * 2}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤...")
                    time.sleep(attempt * 2)

            except urllib.error.URLError as e:
                debug_print(f"      âš ï¸ URLã‚¨ãƒ©ãƒ¼: {e.reason}")
                if attempt < max_retries:
                    debug_print(f"      {attempt * 2}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤...")
                    time.sleep(attempt * 2)

            except Exception as e:
                debug_print(f"      âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
                if attempt < max_retries:
                    debug_print(f"      {attempt * 2}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤...")
                    time.sleep(attempt * 2)

        debug_print(f"      âŒ {max_retries}å›å¤±æ•—")
        return []

    def _parse_xml_reviews(self, xml_data: str) -> List[Dict]:
        """XMLã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡º"""
        reviews = []

        # ã‚ˆã‚Šè©³ç´°ãªãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern = r'<entry>.*?<(?:title|im:name)>(.*?)</\w+>.*?<author>.*?<(?:name)>(.*?)</\w+>.*?<content>(.*?)</content>.*?<(?:im:rating|rating)>(\d+)</\w+>.*?(?:<(?:im:version)>(.*?)</\w+>|version>(.*?)</version>).*?(?:<updated>)(.*?)</updated>.*?</entry>'

        for match in re.finditer(pattern, xml_data, re.DOTALL):
            title = match.group(1).replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
            author = match.group(2).replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
            text = match.group(3).replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
            rating = int(match.group(4))
            version = match.group(5) or match.group(6) or 'N/A'
            date = match.group(7)

            # ã‚¿ã‚¤ãƒˆãƒ«ãŒç©ºã®å ´åˆã€æœ€åˆã®30æ–‡å­—ã‚’ä½¿ã†
            if not title.strip() or title.startswith('â­'):
                title = text[:50] + '...' if len(text) > 50 else text

            reviews.append({
                'title': title,
                'author': author,
                'text': text,
                'rating': rating,
                'version': version,
                'date': date
            })

        return reviews

    def search_app(self, query: str, limit: int = 5) -> List[Dict]:
        """App Storeã§ã‚¢ãƒ—ãƒªã‚’æ¤œç´¢"""
        url = f"https://itunes.apple.com/search?term={urllib.parse.quote(query)}&media=software&limit={limit}"

        try:
            with urllib.request.urlopen(url, timeout=30) as response:
                data = json.loads(response.read().decode('utf-8'))
                return data.get('results', [])
        except Exception as e:
            debug_print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def save_app(self, app_data: Dict) -> int:
        """ã‚¢ãƒ—ãƒªã‚’ä¿å­˜"""
        conn = self._connect()
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO apps (app_id, name, developer, category, rating, url)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            str(app_data.get('trackId', '')),
            app_data.get('trackName', ''),
            app_data.get('artistName', ''),
            app_data.get('primaryGenreName', ''),
            app_data.get('averageUserRating', 0),
            app_data.get('trackViewUrl', '')
        ))

        app_id = cursor.lastrowid
        conn.commit()
        conn.close()

        return app_id

    def save_reviews(self, app_id: int, reviews: List[Dict]) -> int:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜"""
        if not reviews:
            return 0

        conn = self._connect()
        cursor = conn.cursor()

        saved = 0
        for review in reviews:
            try:
                cursor.execute('''
                    INSERT OR IGNORE INTO reviews (app_id, title, text, rating, author, review_date)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    app_id,
                    review.get('title', '')[:200],
                    review.get('text', ''),
                    review.get('rating', 0),
                    review.get('author', '')[:100],
                    review.get('date', '')
                ))

                if cursor.rowcount > 0:
                    saved += 1
            except Exception as e:
                debug_print(f"      âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                continue

        conn.commit()
        conn.close()

        return saved

    def get_bad_reviews(self, app_id: int, limit: int = 50) -> List[Dict]:
        """æ˜Ÿ1ã€œ2ã®æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—"""
        conn = self._connect()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT id, title, text, rating, author, review_date
            FROM reviews
            WHERE app_id = ? AND rating <= 2
            ORDER BY rating ASC, id DESC
            LIMIT ?
        ''', (app_id, limit))

        columns = [desc[0] for desc in cursor.description]
        reviews = [dict(zip(columns, row)) for row in cursor.fetchall()]

        conn.close()

        return reviews

    def analyze_issues(self, bad_reviews: List[Dict]) -> Dict:
        """æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†æ"""
        if not bad_reviews:
            return {
                'themes': [],
                'top_issues': [],
                'summary': 'æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ'
            }

        all_texts = ' '.join([r['text'].lower() for r in bad_reviews])

        issue_patterns = {
            'æ©Ÿèƒ½ä¸è¶³': ['missing', 'feature', 'add', 'need', 'want', 'should have', 'wish', 'æ©Ÿèƒ½', 'è¿½åŠ '],
            'UI/UX': ['ui', 'ux', 'design', 'interface', 'navigation', 'hard to use', 'confusing', 'ã‚ã‹ã‚Šã«ãã„', 'ä½¿ã„ã«ãã„'],
            'ãƒã‚°/å‹•ä½œ': ['bug', 'crash', 'freeze', 'slow', 'lag', 'error', 'doesn\'t work', 'å‹•ã‹ãªã„', 'ãƒã‚°', 'ã‚¯ãƒ©ãƒƒã‚·ãƒ¥'],
            'ä¼šå“¡ç™»éŒ²/åºƒå‘Š': ['ads', 'advertisement', 'subscription', 'pay', 'expensive', 'free', 'premium', 'åºƒå‘Š', 'èª²é‡‘', 'æœ‰æ–™'],
            'é€Ÿåº¦/ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹': ['slow', 'loading', 'wait', 'load time', 'é…ã„', 'é‡ã„', 'æ™‚é–“ãŒã‹ã‹ã‚‹'],
            'é€šçŸ¥': ['notification', 'alert', 'push', 'spam', 'é€šçŸ¥'],
        }

        themes = []
        for theme, keywords in issue_patterns.items():
            count = sum(all_texts.count(kw) for kw in keywords)
            if count > 0:
                themes.append({'theme': theme, 'count': count})

        themes = sorted(themes, key=lambda x: x['count'], reverse=True)[:5]

        issue_counts = {}
        for review in bad_reviews:
            text = review['text'][:80]
            if len(text) > 10:
                issue_counts[text] = issue_counts.get(text, 0) + 1

        top_issues = sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)[:10]

        if themes:
            theme_str = 'ã€'.join([t['theme'] for t in themes[:3]])
            summary = f"ä¸»ãªä¸æº€ãƒ†ãƒ¼ãƒ: {theme_str}"
        else:
            summary = "ç‰¹å®šã®ãƒ†ãƒ¼ãƒã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"

        return {
            'themes': themes,
            'top_issues': top_issues,
            'summary': summary
        }

    def create_analysis_report(self, app_data: Dict, bad_reviews: List[Dict], analysis: Dict) -> str:
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ“± App Store ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 80)

        report.append("\nğŸ“± ã‚¢ãƒ—ãƒªæƒ…å ±")
        report.append("-" * 40)
        report.append(f"åå‰: {app_data.get('trackName', 'N/A')}")
        report.append(f"é–‹ç™ºè€…: {app_data.get('artistName', 'N/A')}")
        report.append(f"ã‚«ãƒ†ã‚´ãƒª: {app_data.get('primaryGenreName', 'N/A')}")
        report.append(f"è©•ä¾¡: â­{app_data.get('averageUserRating', 'N/A')}")

        report.append("\nğŸ“Š æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼çµ±è¨ˆ")
        report.append("-" * 40)
        report.append(f"æ˜Ÿ1ã€œ2ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {len(bad_reviews)}")

        rating_dist = {}
        for r in bad_reviews:
            rating_dist[r['rating']] = rating_dist.get(r['rating'], 0) + 1

        for rating in [1, 2]:
            count = rating_dist.get(rating, 0)
            bar = 'â–ˆ' * (count // 2 + 1)
            report.append(f"  æ˜Ÿ{rating}: {count}ä»¶ {bar}")

        report.append("\nğŸ¯ ä¸æº€ãƒ†ãƒ¼ãƒåˆ†æ")
        report.append("-" * 40)
        for theme in analysis['themes'][:5]:
            bar = 'â–ˆ' * min(theme['count'], 20)
            report.append(f"  {theme['theme']}: {theme['count']}å› {bar}")

        report.append("\nğŸ˜¤ ä¸Šä½ã®ä¸æº€ï¼ˆç¹°ã‚Šè¿”ã•ã‚Œã¦ã„ã‚‹ï¼‰")
        report.append("-" * 40)
        for i, (issue, count) in enumerate(analysis['top_issues'][:10], 1):
            report.append(f"\n{i}. ({count}å›) {issue}")

        report.append("\nğŸ’¬ æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼è©³ç´°ï¼ˆæ˜Ÿ1ã€œ2ï¼‰")
        report.append("-" * 40)
        for i, review in enumerate(bad_reviews[:20], 1):
            stars = 'â­' * review['rating']
            report.append(f"\n{i}. {stars} {review['title'] or '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)'}")
            report.append(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼: {review['author']}")
            report.append(f"   æ—¥ä»˜: {review['review_date']}")
            report.append(f"   ãƒ†ã‚­ã‚¹ãƒˆ: {review['text'][:150]}{'...' if len(review['text']) > 150 else ''}")

        report.append("\nğŸ¤– AIåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        report.append("-" * 40)
        report.append("ä»¥ä¸‹ã®æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’AIã«åˆ†æã•ã›ã‚‹:")
        report.append("---")
        for review in bad_reviews[:30]:
            report.append(f"æ˜Ÿ{review['rating']}: {review['text']}")
        report.append("---")

        report.append("\nğŸ’¡ ãŠã™ã™ã‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
        report.append("-" * 40)
        if analysis['themes']:
            top_theme = analysis['themes'][0]['theme']
            report.append(f"1. æœ€å„ªå…ˆ: {top_theme}ã‚’æ”¹å–„")
            report.append("2. UIã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«ã™ã‚‹")
            report.append("3. å¼·åˆ¶çš„ãªä¼šå“¡ç™»éŒ²ã‚’å‰Šé™¤ã™ã‚‹ï¼ˆã‚ã‚‹å ´åˆï¼‰")
            report.append("4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹")

        report.append("\n" + "=" * 80)

        return "\n".join(report)

    def analyze_app(self, search_query: str, max_reviews: int = 100) -> Dict:
        """ã‚¢ãƒ—ãƒªã‚’åˆ†æ"""
        debug_print(f"\nğŸ” æ¤œç´¢: {search_query}")

        # æ¤œç´¢
        results = self.search_app(search_query, limit=5)
        if not results:
            return {'success': False, 'error': 'ã‚¢ãƒ—ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ'}

        app_data = results[0]
        debug_print(f"ğŸ“± ã‚¢ãƒ—ãƒª: {app_data.get('trackName')}")
        debug_print(f"   é–‹ç™ºè€…: {app_data.get('artistName')}")
        debug_print(f"   è©•ä¾¡: â­{app_data.get('averageUserRating')}")

        # ã‚¢ãƒ—ãƒªã‚’ä¿å­˜
        app_id_db = self.save_app(app_data)
        debug_print(f"âœ… ã‚¢ãƒ—ãƒªä¿å­˜: app_id={app_id_db}")

        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ï¼ˆè¤‡æ•°ã‚«ãƒ†ã‚´ãƒªï¼‰
        debug_print(f"\nğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ä¸­...")
        all_reviews = []

        countries = ['us', 'gb', 'ca', 'au']
        for country in countries:
            debug_print(f"   {country.upper()} ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—...")
            reviews = self.get_reviews_with_retry(app_data.get('trackId', ''), country)
            if reviews:
                debug_print(f"   âœ… {len(reviews)} ä»¶å–å¾—")
                all_reviews.extend(reviews)
            else:
                debug_print(f"   âš ï¸ å–å¾—å¤±æ•—")
            time.sleep(1)

        # é‡è¤‡ã‚’é™¤å»
        unique_reviews = []
        seen = set()
        for review in all_reviews:
            key = (review['author'], review['text'][:50])
            if key not in seen:
                seen.add(key)
                unique_reviews.append(review)

        debug_print(f"   ğŸ“Š ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼: {len(all_reviews)} ä»¶ -> é‡è¤‡é™¤å»: {len(unique_reviews)} ä»¶")

        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜
        if unique_reviews:
            saved = self.save_reviews(app_id_db, unique_reviews)
            debug_print(f"âœ… {saved} ä»¶ä¿å­˜")

        # æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
        debug_print(f"\nğŸ˜¤ æ‚ªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†æä¸­...")
        bad_reviews = self.get_bad_reviews(app_id_db, limit=max_reviews)
        debug_print(f"   æ˜Ÿ1ã€œ2: {len(bad_reviews)} ä»¶")

        # åˆ†æ
        debug_print(f"ğŸ¯ ä¸æº€ã‚’åˆ†æä¸­...")
        analysis = self.analyze_issues(bad_reviews)

        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        debug_print(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­...")
        report = self.create_analysis_report(app_data, bad_reviews, analysis)

        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        report_path = os.path.join(
            os.path.dirname(__file__),
            f"appstore_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
        )
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        debug_print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

        return {
            'success': True,
            'app_name': app_data.get('trackName'),
            'bad_reviews_count': len(bad_reviews),
            'report_path': report_path,
            'analysis': analysis
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description='App Store Top Gainers ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ v2')
    parser.add_argument('--search', '-s', help='æ¤œç´¢ã‚¯ã‚¨ãƒª', required=True)

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ§ª App Store ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ v2")
    print("=" * 60)

    analyzer = AppStoreAnalyzerV2()
    result = analyzer.analyze_app(args.search, max_reviews=100)

    if result['success']:
        print("\n" + "=" * 60)
        print("âœ… å®Œäº†ï¼")
        print("=" * 60)
        print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: {result['report_path']}")
    else:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜')}")


if __name__ == "__main__":
    main()
