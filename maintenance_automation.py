#!/usr/bin/env python3
"""
ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
"""

import os
import json
import shutil
from pathlib import Path
from datetime import datetime

# è¨­å®š
WORKSPACE = Path("/workspace")
BACKUP_DIR = WORKSPACE / "backups"
LOG_DIR = WORKSPACE / "maintenance_logs"
AGENTS_DIR = WORKSPACE / "agents"
MEMORY_DIR = WORKSPACE / "memory"

# ãƒ­ã‚°è¨­å®š
LOG_FILE = LOG_DIR / f"maintenance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

def log(message):
    """ãƒ­ã‚°ã‚’å‡ºåŠ›"""
    print(message)
    LOG_DIR.mkdir(exist_ok=True)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now().isoformat()}] {message}\n")

def backup_important_files():
    """é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    log("=" * 60)
    log("ğŸ“¦ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
    log("=" * 60)

    BACKUP_DIR.mkdir(exist_ok=True)
    LOG_DIR.mkdir(exist_ok=True)

    # æœ¬æ—¥ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    today_backup = BACKUP_DIR / datetime.now().strftime("%Y%m%d")
    today_backup.mkdir(exist_ok=True)

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
    backup_targets = [
        MEMORY_DIR,
        WORKSPACE / "MEMORY.md",
        WORKSPACE / "Plan.md",
        WORKSPACE / "TOOL.md",
        WORKSPACE / "AGENTS.md",
    ]

    backup_count = 0
    for target in backup_targets:
        if target.exists():
            if target.is_dir():
                target_dir = today_backup / target.name
                shutil.copytree(target, target_dir, dirs_exist_ok=True)
                log(f"  âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {target.name}/")
                backup_count += 1
            else:
                shutil.copy2(target, today_backup / target.name)
                log(f"  âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {target.name}")
                backup_count += 1
        else:
            log(f"  âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {target.name}")

    log(f"\nğŸ“Š ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µãƒãƒªãƒ¼: {backup_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")

    # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ï¼ˆ30æ—¥åˆ†ã ã‘æ®‹ã™ï¼‰
    cleanup_old_backups(today_backup)
    log(f"  ğŸ—‘ï¸  å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

    return backup_count

def cleanup_old_backups(keep_backup):
    """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤"""
    all_backups = sorted(BACKUP_DIR.iterdir(), key=lambda x: x.stat().st_mtime, reverse=True)

    # æœ€æ–°ã®30å€‹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’æ®‹ã™
    for old_backup in all_backups[30:]:
        if old_backup.is_dir() and old_backup != keep_backup:
            shutil.rmtree(old_backup)
            log(f"    å‰Šé™¤: {old_backup.name}")

def health_check_agents():
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    log("=" * 60)
    log("ğŸ¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
    log("=" * 60)

    agent_dirs = sorted([d for d in AGENTS_DIR.iterdir() if d.is_dir()])
    required_files = ["agent.py", "db.py", "discord.py", "README.md", "requirements.txt"]

    healthy_agents = []
    unhealthy_agents = []

    for agent_dir in agent_dirs:
        missing_files = []
        for filename in required_files:
            if not (agent_dir / filename).exists():
                missing_files.append(filename)

        if missing_files:
            unhealthy_agents.append({
                "name": agent_dir.name,
                "missing": missing_files,
            })
        else:
            healthy_agents.append(agent_dir.name)

    log(f"\nğŸ“Š ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ:")
    log(f"  ç·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°: {len(agent_dirs)}")
    log(f"  ãƒ˜ãƒ«ã‚·ãƒ¼: {len(healthy_agents)}")
    log(f"  ã‚¢ãƒ³ãƒ˜ãƒ«ã‚·ãƒ¼: {len(unhealthy_agents)}")

    if unhealthy_agents:
        log(f"\nâŒ ã‚¢ãƒ³ãƒ˜ãƒ«ã‚·ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸€è¦§ ({len(unhealthy_agents)}å€‹):")
        for agent in unhealthy_agents[:10]:  # Show first 10
            log(f"  - {agent['name']}: æ¬ æ {', '.join(agent['missing'])}")
        if len(unhealthy_agents) > 10:
            log(f"  ... ã•ã‚‰ã« {len(unhealthy_agents) - 10} å€‹")

    # çµæœã‚’ä¿å­˜
    health_result = {
        "timestamp": datetime.now().isoformat(),
        "total_agents": len(agent_dirs),
        "healthy_agents": len(healthy_agents),
        "unhealthy_agents": len(unhealthy_agents),
        "unhealthy_list": unhealthy_agents,
    }

    health_file = WORKSPACE / "health_check_result.json"
    with open(health_file, "w", encoding="utf-8") as f:
        json.dump(health_result, f, indent=2, ensure_ascii=False)
    log(f"\nğŸ“ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœã‚’ä¿å­˜: {health_file}")

    return {
        "total": len(agent_dirs),
        "healthy": len(healthy_agents),
        "unhealthy": len(unhealthy_agents),
    }

def cleanup_temp_files():
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    log("=" * 60)
    log("ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
    log("=" * 60)

    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    cleanup_patterns = [
        "*.pyc",
        "__pycache__",
        ".DS_Store",
        "Thumbs.db",
        "*.tmp",
        "*.temp",
    ]

    cleaned_count = 0
    cleaned_size = 0

    for root, dirs, files in os.walk(WORKSPACE):
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for d in dirs[:]:
            if d in cleanup_patterns:
                dir_path = Path(root) / d
                if dir_path.exists():
                    size = sum(f.stat().st_size for f in dir_path.rglob("*") if f.is_file())
                    shutil.rmtree(dir_path)
                    log(f"  âœ… å‰Šé™¤: {dir_path.relative_to(WORKSPACE)} ({size:,} bytes)")
                    cleaned_count += 1
                    cleaned_size += size
                    dirs.remove(d)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for f in files:
            for pattern in cleanup_patterns:
                if f.endswith(pattern.replace("*", "")):
                    file_path = Path(root) / f
                    if file_path.exists():
                        size = file_path.stat().st_size
                        file_path.unlink()
                        log(f"  âœ… å‰Šé™¤: {file_path.relative_to(WORKSPACE)} ({size:,} bytes)")
                        cleaned_count += 1
                        cleaned_size += size
                        break

    log(f"\nğŸ“Š ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚µãƒãƒªãƒ¼:")
    log(f"  å‰Šé™¤ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {cleaned_count}å€‹")
    log(f"  è§£æ”¾ã—ãŸå®¹é‡: {cleaned_size:,} bytes ({cleaned_size / 1024 / 1024:.2f} MB)")

    return {
        "cleaned_count": cleaned_count,
        "cleaned_size": cleaned_size,
    }

def check_git_status():
    """Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯"""
    log("=" * 60)
    log("ğŸ“ Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯")
    log("=" * 60)

    import subprocess

    # å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    result = subprocess.run(
        ["git", "status", "--porcelain"],
        cwd=WORKSPACE,
        capture_output=True,
        text=True,
    )

    if result.stdout.strip():
        log(f"\nâš ï¸  æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ãŒã‚ã‚Šã¾ã™:")
        log(result.stdout)
    else:
        log(f"\nâœ… Gitãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã¯ã‚¯ãƒªãƒ¼ãƒ³ã§ã™")

    return result.stdout.strip() != ""

def generate_maintenance_report(results):
    """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    log("=" * 60)
    log("ğŸ“Š ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ")
    log("=" * 60)

    report = {
        "timestamp": datetime.now().isoformat(),
        "results": results,
    }

    report_file = WORKSPACE / f"maintenance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    log(f"\nğŸ“ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_file}")

    return report_file

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    log("ğŸš€ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è‡ªå‹•åŒ–é–‹å§‹")
    log(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    results = {}

    # 1. è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    results["backup"] = backup_important_files()
    log("")

    # 2. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    results["health_check"] = health_check_agents()
    log("")

    # 3. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    results["cleanup"] = cleanup_temp_files()
    log("")

    # 4. Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯
    results["git_status"] = check_git_status()
    log("")

    # 5. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_file = generate_maintenance_report(results)

    end_time = datetime.now()
    duration = (end_time - datetime.now()).total_seconds()

    log("=" * 60)
    log(f"âœ… ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†")
    log(f"çµ‚äº†æ™‚åˆ»: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    log(f"ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    log("=" * 60)

if __name__ == "__main__":
    main()
