#!/usr/bin/env python3
"""
Hacker News ã‚¢ã‚¤ãƒ‡ã‚¢ã¾ã¨ã‚ãƒ»ææ¡ˆãƒ„ãƒ¼ãƒ«
3æ—¥ã”ã¨ã«å®Ÿè¡Œã—ã¦ã€DBã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‹ã‚‰åé›†ãƒ»ã¾ã¨ã‚ã‚‹
"""

import sys
import os
import importlib.util
from datetime import datetime, date
from collections import Counter
import json

# hackernews-scraperã‚’å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
spec = importlib.util.spec_from_file_location("hackernews_scraper", os.path.join(os.path.dirname(__file__), "hackernews-scraper.py"))
hackernews_scraper = importlib.util.module_from_spec(spec)
spec.loader.exec_module(hackernews_scraper)
HackerNewsScraper = hackernews_scraper.HackerNewsScraper
HackerNewsProduct = hackernews_scraper.HackerNewsProduct

class IdeasSummarizer:
    """ã‚¢ã‚¤ãƒ‡ã‚¢ã¾ã¨ã‚ãƒ„ãƒ¼ãƒ«"""

    def __init__(self, db_path: str = None):
        if db_path is None:
            db_path = os.path.join(os.path.dirname(__file__), "data", "producthunt_ideas.db")
        self.scraper = HackerNewsScraper(db_path)
        self.conn = self.scraper._connect()

    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()

    def analyze_topics(self, products: list) -> dict:
        """ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æ"""
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        keywords = []

        for p in products:
            title = p['name'].lower()

            # ä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            tech_keywords = ['ai', 'machine learning', 'ml', 'llm', 'gpt', 'openai',
                          'python', 'javascript', 'rust', 'go', 'zig', 'c', 'c++',
                          'web', 'browser', 'chrome', 'firefox', 'safari',
                          'database', 'sql', 'nosql', 'mongodb', 'postgresql',
                          'api', 'rest', 'graphql',
                          'security', 'privacy', 'encryption',
                          'devops', 'kubernetes', 'docker', 'aws', 'cloud',
                          'blockchain', 'crypto', 'web3', 'nft',
                          'game', 'gaming', 'vr', 'ar', 'metaverse',
                          'linux', 'open source', 'oss', 'github',
                          'startup', 'saas', 'b2b', 'b2c']

            for kw in tech_keywords:
                if kw in title:
                    keywords.append(kw)

        # ã‚«ã‚¦ãƒ³ãƒˆ
        keyword_counts = Counter(keywords)

        return {
            'top_keywords': dict(keyword_counts.most_common(10)),
            'total_keywords': len(keywords)
        }

    def categorize_ideas(self, products: list) -> dict:
        """ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†ã‘"""
        categories = {
            'AI/ML': [],
            'é–‹ç™ºãƒ„ãƒ¼ãƒ«': [],
            'Web/ãƒ–ãƒ©ã‚¦ã‚¶': [],
            'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£/ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼': [],
            'DevOps/ã‚¤ãƒ³ãƒ•ãƒ©': [],
            'ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³/Web3': [],
            'ã‚²ãƒ¼ãƒ ': [],
            'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹': [],
            'ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—/SaaS': [],
            'ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹': [],
            'ãã®ä»–': []
        }

        for p in products:
            title = p['name'].lower()

            if any(kw in title for kw in ['ai', 'machine learning', 'ml', 'llm', 'gpt', 'openai', 'chatbot']):
                categories['AI/ML'].append(p)
            elif any(kw in title for kw in ['api', 'sdk', 'library', 'framework', 'tool', 'cli']):
                categories['é–‹ç™ºãƒ„ãƒ¼ãƒ«'].append(p)
            elif any(kw in title for kw in ['browser', 'chrome', 'firefox', 'safari', 'web', 'html']):
                categories['Web/ãƒ–ãƒ©ã‚¦ã‚¶'].append(p)
            elif any(kw in title for kw in ['security', 'privacy', 'encryption', 'hack', 'vulnerability']):
                categories['ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£/ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼'].append(p)
            elif any(kw in title for kw in ['devops', 'kubernetes', 'docker', 'aws', 'cloud', 'ci/cd']):
                categories['DevOps/ã‚¤ãƒ³ãƒ•ãƒ©'].append(p)
            elif any(kw in title for kw in ['blockchain', 'crypto', 'web3', 'nft', 'bitcoin']):
                categories['ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³/Web3'].append(p)
            elif any(kw in title for kw in ['game', 'gaming', 'vr', 'ar', 'metaverse']):
                categories['ã‚²ãƒ¼ãƒ '].append(p)
            elif any(kw in title for kw in ['database', 'sql', 'nosql', 'mongo', 'postgres']):
                categories['ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹'].append(p)
            elif any(kw in title for kw in ['startup', 'saas', 'platform', 'service']):
                categories['ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—/SaaS'].append(p)
            elif any(kw in title for kw in ['open source', 'oss', 'github', 'repo']):
                categories['ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹'].append(p)
            else:
                categories['ãã®ä»–'].append(p)

        # ç©ºã®ã‚«ãƒ†ã‚´ãƒªã‚’å‰Šé™¤
        return {k: v for k, v in categories.items() if v}

    def generate_recommendations(self, categories: dict) -> list:
        """ãŠã™ã™ã‚ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆ"""
        recommendations = []

        for category, products in categories.items():
            if len(products) >= 3:
                # å„ã‚«ãƒ†ã‚´ãƒªã®ä¸Šä½3ä»¶
                for p in products[:3]:
                    recommendations.append({
                        'title': p['name'],
                        'url': p['url'],
                        'votes': p['votes'],
                        'category': category,
                        'reason': f'{category}ã‚«ãƒ†ã‚´ãƒªã§äººæ°—'
                    })

        # å…¨ä½“ã®ä¸Šä½5ä»¶ã‚‚è¿½åŠ 
        cursor = self.conn.cursor()
        cursor.execute('SELECT name, url, votes FROM products ORDER BY votes DESC LIMIT 5')
        for row in cursor.fetchall():
            if not any(r['url'] == row[1] for r in recommendations):
                recommendations.append({
                    'title': row[0],
                    'url': row[1],
                    'votes': row[2],
                    'category': 'å…¨ã‚«ãƒ†ã‚´ãƒª',
                    'reason': 'ç·åˆäººæ°—'
                })

        return recommendations[:15]

    def create_summary_report(self) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
        # DBã‹ã‚‰å…¨ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆå–å¾—
        cursor = self.conn.cursor()
        cursor.execute('SELECT * FROM products ORDER BY votes DESC')
        columns = [desc[0] for desc in cursor.description]
        all_products = [dict(zip(columns, row)) for row in cursor.fetchall()]

        for p in all_products:
            if p['topics']:
                p['topics'] = json.loads(p['topics'])

        # åˆ†æ
        topic_analysis = self.analyze_topics(all_products)
        categories = self.categorize_ideas(all_products)
        recommendations = self.generate_recommendations(categories)

        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = []
        report.append("=" * 80)
        report.append("ğŸ¯ Hacker News ã‚¢ã‚¤ãƒ‡ã‚¢ã¾ã¨ã‚")
        report.append(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("=" * 80)

        # çµ±è¨ˆ
        report.append("\nğŸ“Š çµ±è¨ˆæƒ…å ±")
        report.append("-" * 40)
        report.append(f"ç·ã‚¢ã‚¤ãƒ‡ã‚¢æ•°: {len(all_products)}")
        report.append(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {len(categories)}")

        if all_products:
            avg_votes = sum(p['votes'] for p in all_products) / len(all_products)
            max_votes = max(p['votes'] for p in all_products)
            report.append(f"å¹³å‡ğŸ‘: {avg_votes:.1f}")
            report.append(f"æœ€é«˜ğŸ‘: {max_votes}")

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        report.append("\nğŸ”‘ äººæ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        report.append("-" * 40)
        if topic_analysis['top_keywords']:
            for kw, count in list(topic_analysis['top_keywords'].items())[:5]:
                report.append(f"  {kw}: {count}å›")

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥
        report.append("\nğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ¥")
        report.append("-" * 40)
        for category, products in sorted(categories.items(), key=lambda x: len(x[1]), reverse=True):
            report.append(f"\nã€{category}ã€‘({len(products)}ä»¶)")
            for p in products[:3]:
                report.append(f"  â€¢ {p['name']} (ğŸ‘{p['votes']})")
            if len(products) > 3:
                report.append(f"  ... ä»–{len(products)-3}ä»¶")

        # ãŠã™ã™ã‚
        report.append("\nğŸ’¡ ãŠã™ã™ã‚ã‚¢ã‚¤ãƒ‡ã‚¢")
        report.append("-" * 40)
        for i, rec in enumerate(recommendations[:10], 1):
            report.append(f"\n{i}. {rec['title']}")
            report.append(f"   ğŸ‘ {rec['votes']} | {rec['category']}")
            report.append(f"   ğŸ’­ {rec['reason']}")
            report.append(f"   ğŸ”— {rec['url']}")

        return "\n".join(report)

    def clear_and_collect(self, limit: int = 30) -> dict:
        """DBã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‹ã‚‰åé›†"""
        print("\nğŸ—‘ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ä¸­...")
        self.scraper.clear_db()
        print("âœ… ã‚¯ãƒªã‚¢å®Œäº†")

        print(f"\nğŸ” Hacker News ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ä¸­ï¼ˆä¸Šä½{limit}ä»¶ï¼‰...")
        stories = self.scraper.get_top_stories(limit=limit)
        print(f"  {len(stories)} ä»¶å–å¾—")

        if stories:
            print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­...")
            saved = self.scraper.save_products(stories)
            print(f"  {saved} ä»¶ä¿å­˜")

            # ã‚µãƒãƒªãƒ¼ä½œæˆ
            print("\nğŸ“ ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆä¸­...")
            summary = self.create_summary_report()

            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            report_path = os.path.join(
                os.path.dirname(__file__),
                f"ideas_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
            )
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(summary)

            print(f"\nğŸ“„ ã‚µãƒãƒªãƒ¼ä¿å­˜: {report_path}")

            # JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            export_path = os.path.join(
                os.path.dirname(__file__),
                f"ideas_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
            )

            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            cursor = self.conn.cursor()
            cursor.execute('SELECT * FROM products ORDER BY votes DESC')
            columns = [desc[0] for desc in cursor.description]
            products = [dict(zip(columns, row)) for row in cursor.fetchall()]

            for p in products:
                if p['topics']:
                    p['topics'] = json.loads(p['topics'])

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(products, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {export_path}")

            return {
                'success': True,
                'products_count': len(stories),
                'summary_path': report_path,
                'export_path': export_path
            }
        else:
            return {
                'success': False,
                'error': 'ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ'
            }

    def create_summary_from_existing(self, limit: int = 50) -> dict:
        """DBã‚’ã‚¯ãƒªã‚¢ã›ãšã«æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§ã‚µãƒãƒªãƒ¼ä½œæˆ"""
        print(f"\nğŸ” Hacker News ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½åŠ å–å¾—ï¼ˆä¸Šä½{limit}ä»¶ï¼‰...")
        stories = self.scraper.get_top_stories(limit=limit)
        print(f"  {len(stories)} ä»¶å–å¾—")

        if stories:
            print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ä¸­...")
            saved = self.scraper.save_products(stories)
            print(f"  {saved} ä»¶ä¿å­˜ï¼ˆé‡è¤‡é™¤å¤–æ¸ˆã¿ï¼‰")

            # ç¾åœ¨ã®DBå†…ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°ã‚’ç¢ºèª
            cursor = self.conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM products')
            total_count = cursor.fetchone()[0]
            print(f"\nğŸ“Š ç¾åœ¨ã®ç·ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°: {total_count}")

            # ã‚µãƒãƒªãƒ¼ä½œæˆ
            print("\nğŸ“ ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆä¸­...")
            summary = self.create_summary_report()

            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            report_path = os.path.join(
                os.path.dirname(__file__),
                f"ideas_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
            )
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(summary)

            print(f"\nğŸ“„ ã‚µãƒãƒªãƒ¼ä¿å­˜: {report_path}")

            # JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            export_path = os.path.join(
                os.path.dirname(__file__),
                f"ideas_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
            )

            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            cursor.execute('SELECT * FROM products ORDER BY votes DESC')
            columns = [desc[0] for desc in cursor.description]
            products = [dict(zip(columns, row)) for row in cursor.fetchall()]

            for p in products:
                if p['topics']:
                    p['topics'] = json.loads(p['topics'])

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(products, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {export_path}")

            return {
                'success': True,
                'products_count': saved,
                'total_count': total_count,
                'summary_path': report_path,
                'export_path': export_path
            }
        else:
            return {
                'success': False,
                'error': 'ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ'
            }

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ¯ Hacker News ã‚¢ã‚¤ãƒ‡ã‚¢ã¾ã¨ã‚ãƒ»ææ¡ˆãƒ„ãƒ¼ãƒ«")
    print(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    summarizer = IdeasSummarizer()
    # DBã‚’ã‚¯ãƒªã‚¢ã›ãšã«ã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ç¶­æŒã—ãŸã¾ã¾ã‚µãƒãƒªãƒ¼ä½œæˆ
    result = summarizer.create_summary_from_existing(limit=50)

    if result['success']:
        print("\n" + "=" * 60)
        print("âœ… å®Œäº†ï¼")
        print("=" * 60)

        # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        print("\n" + summarizer.create_summary_report())
    else:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜')}")

if __name__ == "__main__":
    main()
